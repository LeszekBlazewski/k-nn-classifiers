{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "omW09IVPtqwD",
        "dj89n8ZJQ__d",
        "0Rj8BLZdy0yK",
        "H4_uzZ8nXVx7"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMXfUIOPWLA1dO+TgG+BfnF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeszekBlazewski/MTSwM/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omW09IVPtqwD"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pymUI6t3yx9M",
        "outputId": "14f5249f-4488-41bc-f5c9-b0aecb3be12c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks/MTSwM"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/MTSwM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj89n8ZJQ__d"
      },
      "source": [
        "# Dataset features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDz62EGIRFB7"
      },
      "source": [
        "dataset_features_columns = [\n",
        "    'Age',\n",
        "    'Sex',\n",
        "    # Pain\n",
        "    'Pain location', \n",
        "    'Chest pain radiation', \n",
        "    'Pain character', \n",
        "    'Onset of pain', \n",
        "    'Number of hours since onset', \n",
        "    'Duration of the last episode', \n",
        "    # Associated symptoms\n",
        "    'Nausea', \n",
        "    'Diaphoresis',\n",
        "    'Palpitations',\n",
        "    'Dyspnea',\n",
        "    'Dizziness/syncope',\n",
        "    'Burping',\n",
        "    # Palliative factors\n",
        "    'Palliative factors',\n",
        "    # History of similar pain\n",
        "    'Prior chest pain of this type',\n",
        "    'Physician consulted for prior pain',\n",
        "    'Prior pain related to heart',\n",
        "    'Prior pain due to MI',\n",
        "    'Prior pain due to angina prectoris',\n",
        "    # Past medical history\n",
        "    'Prior MI',\n",
        "    'Prior angina prectoris',\n",
        "    'Prior atypical chest pain',\n",
        "    'Congestive heart failure',\n",
        "    'Peripheral vascular disease',\n",
        "    'Hiatal hernia',\n",
        "    'Hypertension',\n",
        "    'Diabetes',\n",
        "    'Smoker',\n",
        "    # Current medication usage\n",
        "    'Diuretics',\n",
        "    'Nitrates',\n",
        "    'Beta blockers',\n",
        "    'Digitalis',\n",
        "    'Nonsteroidal anti-inflammator',\n",
        "    'Antacids/H2 blockers',\n",
        "    # Physical examinations\n",
        "    'Systolic blood pressure',\n",
        "    'Diastolic blood pressure',\n",
        "    'Heart rate',\n",
        "    'Respiration rate',\n",
        "    'Rales',\n",
        "    'Cyanosis',\n",
        "    'Pallor',\n",
        "    'Systolic murmur',\n",
        "    'Diastolic murmur',\n",
        "    'Oedema',\n",
        "    'S3 gallop',\n",
        "    'S4 gallop',\n",
        "    'Chest wall tenderness',\n",
        "    'Diaphoresis',\n",
        "    # ECG examination\n",
        "    'New Q wave',\n",
        "    'Any Q wave',\n",
        "    'New ST segment elevation',\n",
        "    'Any ST segment elevation',\n",
        "    'New ST segment depression',\n",
        "    'Any ST segment depression',\n",
        "    'New T wave inversion',\n",
        "    'Any T wave inversion',\n",
        "    'New intraventricular conduction defect',\n",
        "    'Any intraventricular conduction defect',\n",
        "    'Class'\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Rj8BLZdy0yK"
      },
      "source": [
        "# Load & merge datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16oiFuUty2_Y"
      },
      "source": [
        "data_list = []\n",
        "\n",
        "for i, file in enumerate(glob.glob(\"data/*.txt\"), 1):\n",
        "  data_set = pd.read_csv(file,sep=\"\\t\", header=None).transpose()\n",
        "  data_set['Class'] = i\n",
        "  data_list.append(data_set)\n",
        "\n",
        "dataset = pd.concat(data_list, axis=0)\n",
        "\n",
        "dataset.columns = dataset_features_columns\n",
        "\n",
        "dataset.info()\n",
        "#dataset.head()\n",
        "#dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4_uzZ8nXVx7"
      },
      "source": [
        "# Features ranking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgdCmgGdDF_R"
      },
      "source": [
        "## SelectKBest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqC6rnTNXYjZ"
      },
      "source": [
        "def build_features_ranking(x, y, score_func):\n",
        "    features_num = x.shape[1]\n",
        "    k_best_selector = SelectKBest(score_func=score_func, k=features_num) \n",
        "    k_best_selector.fit(x, y)\n",
        "    scores_ranking = [\n",
        "        (name, round(score, 2))\n",
        "        for name, score in zip(x.columns, k_best_selector.scores_)\n",
        "    ]\n",
        "    scores_ranking.sort(reverse=True, key=lambda x: x[1])\n",
        "    return scores_ranking"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4KfVyr9DzF4"
      },
      "source": [
        "def print_features_ranking_with_plot(features_ranking, used_score_func):\n",
        "  print(f'Features ranking after using {used_score_func} score function:')\n",
        "  for i, feature in enumerate(features_ranking, 1):\n",
        "    print(f\"{i}. {feature[0]} {feature[1]}\")\n",
        "  # display bar plot\n",
        "  plt.figure(figsize=(30,20))\n",
        "  estimator_num = len(features_ranking)\n",
        "  # sort ascending because horizontal bars print in reverse order\n",
        "  ascending_features = sorted([(f[0], f[1]) for f in features_ranking], key=lambda f: f[1])\n",
        "  plt.barh(range(estimator_num), [feature[1] for feature in ascending_features], align='center') # extract score value\n",
        "  plt.yticks(range(estimator_num), [feature[0] for feature in ascending_features]) # extract the feature label\n",
        "  plt.title(f'Ranking based on {used_score_func}')\n",
        "  plt.show()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vwxZyYhZoVJ"
      },
      "source": [
        "x = dataset.drop('Class', axis=1)\n",
        "y = dataset['Class']\n",
        "# f_classif: ANOVA test (F-value between label/feature for regression tasks)\n",
        "features_ranking_classif = build_features_ranking(x, y, f_classif)\n",
        "print_features_ranking_with_plot(features_ranking_classif, 'f_classif')\n",
        "# chi-squared stats of non-negative features for classification tasks.\n",
        "features_ranking_chi = build_features_ranking(x, y, chi2)\n",
        "print_features_ranking_with_plot(features_ranking_chi, 'chi2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eQbRj5UR-8u"
      },
      "source": [
        "# Evaluation of the classifier with cross validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDNla5e1Wu-w"
      },
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "def evaluate_and_get_classifiers(classfier,features_set,y):\n",
        "  # prepare the cross-validation procedure\n",
        "  validator = RepeatedKFold(n_splits=2, n_repeats=5, random_state=0)\n",
        "  # evaluate model\n",
        "  cv_results = cross_validate(classfier,features_set,y,cv=validator,scoring='accuracy',return_estimator=True)\n",
        "  # report performance\n",
        "  mean = np.mean(cv_results['test_score'])\n",
        "  return (mean,cv_results['estimator'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hku7Jqv9xE_O"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXAuNn-cxJUU"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def build_and_plot_confustion_matrix(x,y,best_classifiers):\n",
        "  confusion_matrix = []\n",
        "  for classifier in best_classifiers:\n",
        "    y_pred = classifier.predict(x)\n",
        "    confusion_matrix += y_pred\n",
        "\n",
        "\n",
        "\n",
        "# Here eiither use aggregated confusion matrix from the best classifiers or use cross_val_predict function"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGXwyYa0dNWq"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7UbQGATTHIs",
        "outputId": "8d871caf-294f-43c1-f567-cf14c8693d1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "x = dataset.drop('Class', axis=1)\n",
        "y = dataset['Class']\n",
        "\n",
        "features_ranking = build_features_ranking(x,y,f_classif)\n",
        "feature_names = [feature[0] for feature in features_ranking] # convert to only class names\n",
        "\n",
        "number_of_neighbours=(1,5,10)\n",
        "metrics=('euclidean','manhattan')\n",
        "\n",
        "result_columns = ['features_count', 'neighbours_count', 'metric', 'mean_accuracy']\n",
        "results = []\n",
        "best_classifiers = []\n",
        "maximum_features = 5\n",
        "\n",
        "# for each metric\n",
        "for metric in metrics:\n",
        "  # for each k neighbours\n",
        "  for neighbours_count in number_of_neighbours:\n",
        "    # append features on the way\n",
        "    for features_count in range(1, maximum_features+1):\n",
        "      # include in the dataset only features selected from ranking in given run\n",
        "      x = dataset.drop(dataset.columns.difference(feature_names[:features_count]), 1)\n",
        "      # construct the classifier\n",
        "      knn_classifier = KNeighborsClassifier(n_neighbors=neighbours_count, metric=metric)\n",
        "      # perfomr the Cross validation process and get results\n",
        "      current_result_mean, classifiers = evaluate_and_get_classifiers(knn_classifier,x,y)\n",
        "      # save the best set of classifiers\n",
        "      if all(result[3] <= current_result_mean for result in results):\n",
        "        best_classifiers = classifiers\n",
        "      results.append([features_count, neighbours_count, metric, current_result_mean])\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.columns = result_columns\n",
        "print(results_df.head())\n",
        "print(f\"max accuracy: {results_df['mean_accuracy'].max()}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   features_count  neighbours_count     metric  mean_accuracy\n",
            "0               1                 1  euclidean       0.511654\n",
            "1               2                 1  euclidean       0.501487\n",
            "2               3                 1  euclidean       0.502142\n",
            "3               4                 1  euclidean       0.528111\n",
            "4               5                 1  euclidean       0.524113\n",
            "max accuracy: 0.5281108647450111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QgWaKiTVgv6"
      },
      "source": [
        "1. Puszczam ranking cech\n",
        "2. Dla zestawów:\n",
        "```\n",
        "k=1,metric=euclidean\n",
        "k=5,metric=euclidean\n",
        "k=10,metric=euclidean\n",
        "```\n",
        "```\n",
        "k=1,metric=manhattan\n",
        "k=5,metric=manhattan\n",
        "k=10,metric=manhattan\n",
        "```\n",
        "\n",
        "wykonuję testy dodając kolejno po klasie z rankingu.\n",
        "\n",
        "3. Zapisuje wszystkie wyniki (średnie) z uzyskanych przebiegów w tablicy.\n",
        "4. Podczas iteracji sprawdzam, czy obecnie uzyskana średnia z całego przebiegu jest większa od jakiejkolwiek już uzyskanej i jeśli tak to zapisuje zestaw estymatorów uzyskanych w tym przebiegu(posłużą do wyciągnięcia macierzy konfuzji)\n",
        "5. Wyznaczam sumę macierzy konfuzji z wyciągniętych klasyfikatorów\n",
        "6. Analiza statystyczna wyników (pytanie czy średnich pomiędzy całymi iteracjami czy wyników w danym obiegu KFolda)."
      ]
    }
  ]
}